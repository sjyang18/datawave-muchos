
######## Ansible overrides for the DataWave build #######################################################

security.use.testauthservice={{ dw_security_use_test_authservice | lower | default(false) }}
{% if dw_security_use_test_authservice -%}
security.testauthservice.context.entry=<value>classpath*:datawave/security/TestDatawaveUserServiceConfiguration.xml</value>
security.testauthservice.users= \
\n        <value><![CDATA[ \
\n        { \
\n            "dn": { \
\n                 "subjectDN": "{{ dw_test_user_subject_dn }}", \
\n                 "issuerDN": "{{ dw_test_user_issuer_dn }}" \
\n        }, \
\n        "userType": "USER",\
\n        "auths": [ {% for auth in dw_test_user_accumulo_auths %}"{{ auth }}"{% if not loop.last %}, {% endif %}{% endfor %} ], \
\n        "roles": [ {% for role in dw_test_user_webservice_roles %}"{{ role }}"{% if not loop.last %}, {% endif %}{% endfor %} ], \
\n        "creationTime": -1, \
\n        "expirationTime": -1 \
\n        } \
\n        ]]></value>
{% endif %}

QUERY_METRICS_BASE_NAME=datawave.queryMetrics

WAREHOUSE_HDFS_NAME_NODE={{ hdfs_root }}
WAREHOUSE_ZOOKEEPERS={{ zookeeper_connect }}
WAREHOUSE_ACCUMULO_HOME={{ accumulo_home }}
WAREHOUSE_INSTANCE_NAME={{ accumulo_instance }}
WAREHOUSE_JOBTRACKER_NODE={{ dw_yarn_resource_manager }}
WAREHOUSE_HADOOP_CONF={{ dw_warehouse_hadoop_conf_dir }}

INGEST_HDFS_NAME_NODE={{ hdfs_root }}
INGEST_ZOOKEEPERS={{ zookeeper_connect }}
INGEST_ACCUMULO_HOME={{ accumulo_home }}
INGEST_INSTANCE_NAME={{ accumulo_instance }}
INGEST_JOBTRACKER_NODE={{ dw_yarn_resource_manager }}
INGEST_HADOOP_CONF={{ dw_ingest_hadoop_conf_dir }}

# Note the max blocks per job must be less than or equal to the number of mappers

INGEST_BULK_JOBS={{ dw_bulk_max_ingest_jobs }}
INGEST_BULK_MAPPERS={{ dw_bulk_max_files_per_job }}
INGEST_MAX_BULK_BLOCKS_PER_JOB={{ dw_bulk_max_files_per_job }}

INGEST_LIVE_JOBS={{ dw_live_max_ingest_jobs }}
INGEST_LIVE_MAPPERS={{ dw_live_max_files_per_job }}
INGEST_MAX_LIVE_BLOCKS_PER_JOB={{ dw_live_max_files_per_job }}

BULK_INGEST_DATA_TYPES={{ dw_bulk_ingest_data_types | default() }}
BULK_CHILD_MAP_MAX_MEMORY_MB={{ dw_bulk_child_map_max_memory_mb }}
BULK_CHILD_REDUCE_MAX_MEMORY_MB={{ dw_bulk_child_reduce_max_memory_mb }}
BULK_INGEST_REDUCERS={{ dw_bulk_ingest_reducers }}
NUM_MAP_LOADERS={{ dw_bulk_num_map_loaders }}

LIVE_INGEST_DATA_TYPES={{ dw_live_ingest_data_types | default() }}
LIVE_CHILD_MAP_MAX_MEMORY_MB={{ dw_live_child_map_max_memory_mb }}
LIVE_CHILD_REDUCE_MAX_MEMORY_MB=0
LIVE_INGEST_REDUCERS=0

# extra CHILD_OPTS (java options)
CHILD_INGEST_OPTS=

PASSWORD={{ accumulo_password }}
ZOOKEEPER_HOME={{ zookeeper_home }}
HADOOP_HOME={{ hadoop_home }}
MAPRED_HOME={{ hadoop_home }}
HDFS_BASE_DIR={{ dw_hdfs_base_dir }}
BASE_WORK_DIR={{ dw_hdfs_base_dir }}/work
MAPRED_INGEST_OPTS={{ dw_mapred_ingest_opts }}
LOG_DIR={{ dw_ingest_log_dir }}
FLAG_DIR={{ dw_ingest_flag_dir }}
FLAG_MAKER_CONFIG={{ dw_flag_maker_configs }}
BIN_DIR_FOR_FLAGS={{ dw_ingest_home }}/bin
EVENT_DISCARD_INTERVAL={{ dw_event_discard_interval }}
KEYSTORE={{ dw_keystore }}
KEYSTORE_TYPE={{ dw_keystore_type }}
KEYSTORE_PASSWORD={{ dw_keystore_password }}
TRUSTSTORE={{ dw_truststore }}
FLAG_METRICS_DIR={{ dw_flag_metrics_dir }}
TRUSTSTORE_TYPE={{ dw_truststore_type }}
JOB_CACHE_REPLICATION={{ dw_job_cache_replication }}
EDGE_DEFINITION_FILE={{ dw_edge_definition_file }}
DATAWAVE_INGEST_HOME={{ dw_ingest_home }}
PASSWORD_INGEST_ENV={{ dw_ingest_secrets_file }}
JAVA_HOME={{ java_home }}
NUM_SHARDS={{ dw_num_shards }}

table.shard.numShardsPerDay={{ dw_num_shards }}
hdfs.site.config.urls=file://{{ dw_warehouse_hadoop_conf_dir }}/core-site.xml,file://{{ dw_warehouse_hadoop_conf_dir }}/hdfs-site.xml
accumulo.instance.name={{ accumulo_instance }}
accumulo.user.password={{ accumulo_password }}
cached.results.hdfs.uri={{ hdfs_root }}
lock.file.dir={{ dw_ingest_lockfile_dir }}
server.keystore.password={{ dw_keystore_password }}
mysql.user.password={{ dw_mysql_user_password }}
jboss.jmx.password={{ dw_jboss_jmx_password }}
hornetq.cluster.password={{ dw_hornetq_cluster_password }}
hornetq.system.password={{ dw_hornetq_system_password }}
mapReduce.job.tracker={{ dw_yarn_resource_manager }}
bulkResults.job.tracker={{ dw_yarn_resource_manager }}
ingest.data.types={{ dw_all_ingest_data_types | join(",") }}
zookeeper.hosts={{ zookeeper_connect }}

jboss.managed.executor.service.default.max.threads=64

datawave.docs.menu.extras=<li><a href="http://{{ groups['accumulomaster'][0] }}:9995">Accumulo</a></li>

